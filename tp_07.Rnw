\documentclass{article}

\begin{document}
\SweaveOpts{concordance=TRUE}

\begin{center}
	
    \textbf{\large UNIVERSIDADE FEDERAL DE MINAS GERAIS}
    \textbf{\large ESCOLA DE ENGENHARIA}\\*
    \textbf{DEPARTAMENTO DE ENGENHARIA ELETRICA}\\*
    \textbf{GRADUACAO EM ENGENHARIA ELETRICA}
	\vfill

	\textbf{\Large Exercício 7 - Solução de Problema Tarefa
}\vfill
\end{center}

\begin{center}
	{\large  Guilherme Junio Silva Passos (2011016244)\\*}\vfill
\end{center}

\begin{minipage}{0.5\textwidth}
    Trabalho apresentado à disciplina de Redes Neurais Artificiais\\[1.5ex]
	Professor: Antonio de Padua Braga
\end{minipage}\vfill

\begin{center}
	{\large Belo Horizonte\\11/06/2017}
	\pagebreak
\end{center}

\section{Introdução do Problema}
 Ir-se-á avaliavar o desempenho do treinamento de três funções de aprendizado disntitas de uma Rede Neural do tipo MLP (Perceptron de Multicamadas). O conjunto de dados utilizado representa o comportamento de uma balança de equilibrio de apontar para esquerda, estar balanceada e apontar para a direita quando se varia a massa em dos seus lados ou a distância desta para o centro da balança.\\*
 
 \section{Informações sobre o conjunto de Dados}
Os dados foram gerados a fim de se modelar resultados de experimentos psicológicos. Cada amostra é classificada pela indicação da balança de equilíbrio em: apontar para esquerda, equilibrada e apontar para a direita. Os atributos de entrada são peso à esquerda (PE), distância para a esquerda (DE), peso à direita (PD), distância para direita (DD) e cada um deles estão mensurado numa escala que varia de 1 a 5. A maneira correta para se encontrar a indicação da balança é avaliar qual dos produtos (PE*DE) (PD*DD) é o maior. Se eles forem iguais, a balança está equilibriada. 

Exemplo do conjutos de Dados

1. Class Name: 3 (L, B, R) 

2. Left-Weight: 5 (1, 2, 3, 4, 5) 

3. Left-Distance: 5 (1, 2, 3, 4, 5) 

4. Right-Weight: 5 (1, 2, 3, 4, 5) 

5. Right-Distance: 5 (1, 2, 3, 4, 5)
 
\section{Treinamento da Rede Neural de Multicamadas}

<<echo=T, fig=T>>=

cat("\014")

#Biblotecas importantes
library(splitstackshape)
library(RSNNS)
library(ggplot2)

#Configurando o diretório de trabalho
setwd("C:\\Users\\passsos\\Dropbox\\Public\\UFMG\\Redes Neurais\\Atividade 07")

#Carregando os dados
myDataSet <-as.matrix(read.table("balance-scale.txt"))


#Organizando os dados no formato matricial
myDataSet <- as.data.frame.array(myDataSet)


#Separando os dados em colunas 
myDataSet <- cSplit(myDataSet, splitCols = "V1",sep = ",")


#Nomenado as Colunas
colnames(myDataSet) <- c("Class Name","Left-Weight","Left-Distance","Right-Weight", "Right-Distance")

#Dados
myDataSet


#Determinação da colunas de entrada do conjunto de dados (X)
myDataSet_Values <- myDataSet[,2:5]

#Codificação das classes do problema (Y)
myDataSet_Targets <- decodeClassLabels(myDataSet[[1]], valTrue=1, valFalse=0)

#Separando os conjuntos de treinamento e teste do modelo
myDataSet <- splitForTrainingAndTest(myDataSet_Values, myDataSet_Targets, ratio=0.15)
  
#Modelo 
model <- mlp(x=myDataSet$inputsTrain, y=myDataSet$targetsTrain, size=5, learnFunc="Std_Backpropagation", learnFuncParams=c(0.1), maxit=100, inputsTest=myDataSet$inputsTest, targetsTest=myDataSet$targetsTest)

#Resumo do Modelo
summary(model)
model

par(mfrow=c(2,2))
plotIterativeError(model)

#Resultado do treinamento
predictions <- predict(model,myDataSet$inputsTest)
#Matriz de 
cm <- confusionMatrix(myDataSet$targetsTrain, encodeClassLabels(fitted.values(model),
                                                      method="402040", l=0.4, h=0.6))
#Acuaracia do modelo
acuracia_Std_Backpropagation <- sum(diag(cm))/ sum(cm)


#-------------------------------------------------------------------------------

#Modelo 
model <- mlp(x=myDataSet$inputsTrain, y=myDataSet$targetsTrain, size=5, learnFunc="Rprop", learnFuncParams=c(0.1), maxit=100, inputsTest=myDataSet$inputsTest, targetsTest=myDataSet$targetsTest)

#Resumo do Modelo
summary(model)
model

par(mfrow=c(2,2))
plotIterativeError(model)

#Resultado do treinamento
predictions <- predict(model,myDataSet$inputsTest)
#Matriz de 
cm <- confusionMatrix(myDataSet$targetsTrain, encodeClassLabels(fitted.values(model),
                                                      method="402040", l=0.4, h=0.6))
#Acuaracia do modelo
acuracia_Rprop <- sum(diag(cm))/ sum(cm)


#-------------------------------------------------------------------------------

#Modelo 
model <- mlp(x=myDataSet$inputsTrain, y=myDataSet$targetsTrain, size=5, learnFunc="BackpropChunk", learnFuncParams=c(0.1), maxit=100, inputsTest=myDataSet$inputsTest, targetsTest=myDataSet$targetsTest)

#Resumo do Modelo
summary(model)
model

par(mfrow=c(2,2))
plotIterativeError(model)

#Resultado do treinamento
predictions <- predict(model,myDataSet$inputsTest)
#Matriz de 
cm <- confusionMatrix(myDataSet$targetsTrain, encodeClassLabels(fitted.values(model),
                                                      method="402040", l=0.4, h=0.6))
#Acuaracia do modelo
acuracia_BackpropChunk <- sum(diag(cm))/ sum(cm)

acuracia_Std_Backpropagation

acuracia_Rprop

acuracia_BackpropChunk


@


\end{document}